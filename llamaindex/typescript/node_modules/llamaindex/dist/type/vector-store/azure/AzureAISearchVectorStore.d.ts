import { AzureKeyCredential, KnownVectorSearchAlgorithmKind, KnownVectorSearchCompressionKind, type LexicalAnalyzerName, SearchClient, SearchIndexClient } from "@azure/search-documents";
import { DefaultAzureCredential, ManagedIdentityCredential } from "@azure/identity";
import { type BaseNode } from "@llamaindex/core/schema";
import { BaseVectorStore, type MetadataFilters, type VectorStoreBaseParams, type VectorStoreQuery, type VectorStoreQueryResult } from "../types.js";
import { type R } from "./AzureAISearchVectorStoreConfig.js";
/**
 * Enumeration representing the supported index management operations
 */
export declare enum IndexManagement {
    NO_VALIDATION = "NoValidation",
    VALIDATE_INDEX = "ValidateIndex",
    CREATE_IF_NOT_EXISTS = "CreateIfNotExists"
}
/**
 * Enumeration representing the supported types for metadata fields in an
 * Azure AI Search Index, corresponds with types supported in a flat
 * metadata dictionary.
 */
export declare enum MetadataIndexFieldType {
    STRING = "Edm.String",
    BOOLEAN = "Edm.Boolean",
    INT32 = "Edm.Int32",
    INT64 = "Edm.Int64",
    DOUBLE = "Edm.Double",
    COLLECTION = "Collection(Edm.String)"
}
/**
 * Embeddings and documents are stored in an Azure AI Search index,
 * a merge or upload approach is used when adding embeddings.
 * When adding multiple embeddings the index is updated by this vector store
 * in batches of 10 documents, very large nodes may result in failure due to
 * the batch byte size being exceeded.
 */
export interface AzureAISearchOptions<T extends R> {
    userAgent?: string;
    credential?: AzureKeyCredential | DefaultAzureCredential | ManagedIdentityCredential;
    endpoint?: string;
    key?: string;
    serviceApiVersion?: string;
    indexName?: string;
    indexClient?: SearchIndexClient;
    indexManagement?: IndexManagement;
    searchClient?: SearchClient<T>;
    languageAnalyzer?: LexicalAnalyzerName;
    compressionType?: KnownVectorSearchCompressionKind;
    embeddingDimensionality?: number;
    vectorAlgorithmType?: KnownVectorSearchAlgorithmKind;
    /**
     * Index field storing the id
     */
    idFieldKey?: string | undefined;
    /**
     * Index field storing the node text
     */
    chunkFieldKey?: string | undefined;
    /**
     * Index field storing the embedding vector
     */
    embeddingFieldKey?: string | undefined;
    /**
     * Index field storing node metadata as a json string.
     * Schema is arbitrary, to filter on metadata values they must be stored
     * as separate fields in the index, use filterable_metadata_field_keys
     * to specify the metadata values that should be stored in these filterable fields
     */
    metadataStringFieldKey?: string | undefined;
    /**
     * Index field storing doc_id
     */
    docIdFieldKey?: string | undefined;
    /**
     * List of index fields that should be hidden from the client.
     * This is useful for fields that are not needed for retrieving,
     * but are used for similarity search, like the embedding field.
     */
    hiddenFieldKeys?: string[] | undefined;
    filterableMetadataFieldKeys?: FilterableMetadataFieldKeysType | undefined;
    /**
     * (Optional) function used to map document fields to the AI search index fields
     * If none is specified a default mapping is provided which uses
     *  the field keys. The keys in the enriched document are:
     *   `["id", "chunk", "embedding", "metadata"]`.
     *
     *   The default mapping is:
     *   - `"id"` to idFieldKey
     *   - `"chunk"` to chunkFieldKey
     *   - `"embedding"` to embeddingFieldKey
     *   - `"metadata"` to metadataFieldKey
     * @param enrichedDoc The enriched document
     * @param metadata The metadata of the document
     * @returns The mapped index document
     */
    indexMapping?: (enrichedDoc: BaseNode, metadata: Record<string, unknown>) => T;
}
export type FilterableMetadataFieldKeysType = Array<string> | Map<string, string> | Map<string, [string, MetadataIndexFieldType]>;
/**
 * Azure AI Search vector store.
 *
 * @example
```typescript
import { DefaultAzureCredential, getBearerTokenProvider} from "@azure/identity";
import {KnownAnalyzerNames, KnownVectorSearchAlgorithmKind } from "@azure/search-documents";

// 1- Setup Azure OpenAI
const azureADTokenProvider = getBearerTokenProvider(
  new DefaultAzureCredential(),
  "https://cognitiveservices.azure.com/.default",
);

// IMPORTANT: You need to deploy your own embedding model as well as your own chat completion model
// NOTE: You can use whatever embedding model and language model that is supported in LlamaIndex
const azure = {
  azureADTokenProvider,
  deployment: process.env.AZURE_DEPLOYMENT_NAME,
};
Settings.llm = new OpenAI({ azure });
Settings.embedModel = new OpenAIEmbedding({
  model: process.env.EMBEDDING_MODEL,
  azure: {
    ...azure,
    deployment: process.env.EMBEDDING_MODEL,
  },
});

// ---------------------------------------------------------
// 2- Setup Azure AI Search
// Define env variables in .env file
// AZURE_AI_SEARCH_ENDPOINT=
// AZURE_AI_SEARCH_KEY=
// AZURE_OPENAI_ENDPOINT=
// EMBEDDING_MODEL=text-embedding-ada-002
// AZURE_DEPLOYMENT_NAME=gpt-4
// AZURE_API_VERSION=2024-09-01-preview

// Define index name
const indexName = "llamaindex-vector-store";

// ---------------------------------------------------------
// 3a- Create Index (if it does not exist)
// id:	      Edm.String
// chunk:	    Edm.String
// embedding:	Collection(Edm.Single)
// metadata:	Edm.String
// doc_id:	  Edm.String
// author:	  Edm.String
// theme:	    Edm.String
// director:	Edm.String

// Define metadata fields with their respective configurations
const metadataFields = {
  author: "author",
  theme: ["theme", MetadataIndexFieldType.STRING],
  director: "director",
};

// Define index parameters and vector store configuration
// Index validation:
// - IndexManagement.VALIDATE_INDEX: will validate before creating emnbedding index and will throw a runtime error if the index does not exist
// - IndexManagement.NO_VALIDATION: will try to access the index and will throw a runtime error if the index does not exist
// - IndexManagement.CREATE_IF_NOT_EXISTS: will create the index if it does not exist

const vectorStore = new AzureAISearchVectorStore({
  filterableMetadataFieldKeys:
    metadataFields as unknown as FilterableMetadataFieldKeysType,
  indexName,
  indexManagement: IndexManagement.CREATE_IF_NOT_EXISTS,
  idFieldKey: "id",
  chunkFieldKey: "chunk",
  embeddingFieldKey: "embedding",
  metadataStringFieldKey: "metadata",
  docIdFieldKey: "doc_id",
  embeddingDimensionality: 1536,
  hiddenFieldKeys: ["embedding"],
  languageAnalyzer: KnownAnalyzerNames.EnLucene,
  // store vectors on disk
  vectorAlgorithmType: KnownVectorSearchAlgorithmKind.ExhaustiveKnn,

  // Optional: Set to "scalar" or "binary" if using HNSW
  compressionType: KnownVectorSearchCompressionKind.BinaryQuantization,
});

// ---------------------------------------------------------
// 3a- Loading documents
// Load the documents stored in the data/paul_graham/ using the SimpleDirectoryReader
// NOTE: You can use whatever reader that is supported in LlamaIndex

// Load documents using a directory reader
const documents = await new SimpleDirectoryReader().loadData(
  "data/paul_graham/",
);
const storageContext = await storageContextFromDefaults({ vectorStore });

// Create index from documents with the specified storage context
const index = await VectorStoreIndex.fromDocuments(documents, {
  storageContext,
  docStoreStrategy: DocStoreStrategy.UPSERTS,
});

const queryEngine = index.asQueryEngine();
const response = await queryEngine.query({
  query: "What did the author do growing up?",
  similarityTopK: 3,
} as any);
console.log({ response });
 */
export declare class AzureAISearchVectorStore<T extends R> extends BaseVectorStore {
    #private;
    storesText: boolean;
    _searchClient: SearchClient<T> | undefined;
    _indexClient: SearchIndexClient | undefined;
    flatMetadata: boolean;
    constructor(options: AzureAISearchOptions<T> & VectorStoreBaseParams);
    createSearchIndexClient(options: AzureAISearchOptions<T>): void;
    createSearchClient(options: AzureAISearchOptions<T>): void;
    /**
     * Get search client
     * @returns Azure AI Search client. See {@link SearchClient}
     */
    client(): SearchClient<T> | undefined;
    /**
     * Get index client
     * @returns Azure AI Search index client. See {@link SearchIndexClient}
     */
    indexClient(): SearchIndexClient | undefined;
    /**
     * Add nodes to index associated with the configured search client.
     * @param nodes List of nodes with embeddings to add to the index
     * @returns List of node IDs that were added to the index
     */
    add(nodes: BaseNode[]): Promise<string[]>;
    /**
     * Delete documents from the AI Search Index with docIdFieldKey (doc_id) field equal to refDocId.
     * @param refDocId The reference document ID to delete from the index
     */
    delete(refDocId: string): Promise<void>;
    /**
     * Get nodes asynchronously from the Azure AI Search index.
     * @param nodeIds List of node IDs to retrieve from the index
     * @param filters Metadata filters to apply to the search
     * @param limit Maximum number of nodes to retrieve
     * @returns List of nodes retrieved from the index
     */
    getNodes(nodeIds?: string[], filters?: MetadataFilters, limit?: number): Promise<BaseNode[]>;
    query(query: VectorStoreQuery & {
        queryStr: string;
    }): Promise<VectorStoreQueryResult>;
}
