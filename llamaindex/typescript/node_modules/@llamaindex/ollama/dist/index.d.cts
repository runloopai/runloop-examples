import { LLMAgentParams, LLMAgentWorker, LLMAgent } from '@llamaindex/core/agent';
import { ToolCallLLM, LLMMetadata, LLMChatParamsStreaming, ToolCallLLMMessageOptions, ChatResponseChunk, LLMChatParamsNonStreaming, ChatResponse, LLMCompletionParamsStreaming, CompletionResponse, LLMCompletionParamsNonStreaming, BaseTool } from '@llamaindex/core/llms';
import { Tool } from 'ollama';
import { Config, Options, Ollama as Ollama$1 } from 'ollama/browser';
import { BaseEmbedding } from '@llamaindex/core/embeddings';

type OllamaParams = {
    model: string;
    config?: Partial<Config>;
    options?: Partial<Options>;
};
declare class Ollama extends ToolCallLLM {
    supportToolCall: boolean;
    readonly ollama: Ollama$1;
    model: string;
    options: Partial<Omit<Options, "num_ctx" | "top_p" | "temperature">> & Pick<Options, "num_ctx" | "top_p" | "temperature">;
    constructor(params: OllamaParams);
    get metadata(): LLMMetadata;
    chat(params: LLMChatParamsStreaming<ToolCallLLMMessageOptions>): Promise<AsyncIterable<ChatResponseChunk>>;
    chat(params: LLMChatParamsNonStreaming<ToolCallLLMMessageOptions>): Promise<ChatResponse<ToolCallLLMMessageOptions>>;
    complete(params: LLMCompletionParamsStreaming): Promise<AsyncIterable<CompletionResponse>>;
    complete(params: LLMCompletionParamsNonStreaming): Promise<CompletionResponse>;
    static toTool(tool: BaseTool): Tool;
}

type OllamaAgentParams = LLMAgentParams<Ollama> & {
    model?: string;
};
declare class OllamaAgentWorker extends LLMAgentWorker {
}
declare class OllamaAgent extends LLMAgent {
    constructor(params: OllamaAgentParams);
}

declare class OllamaEmbedding extends BaseEmbedding {
    private readonly llm;
    constructor(params: OllamaParams);
    private getEmbedding;
    getTextEmbedding(text: string): Promise<number[]>;
}

export { Ollama, OllamaAgent, type OllamaAgentParams, OllamaAgentWorker, OllamaEmbedding, type OllamaParams };
