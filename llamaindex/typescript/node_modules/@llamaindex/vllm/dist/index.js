import { OpenAI } from '@llamaindex/openai';

class VLLM extends OpenAI {
    constructor(params){
        super({
            additionalSessionOptions: {
                baseURL: "http://localhost:8000/v1"
            },
            model: params.model,
            apiKey: "token-abc123"
        });
    }
}

export { VLLM };
